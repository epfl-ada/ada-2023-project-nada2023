{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read the tsv files in MovieSummaries\n",
    "load_movies = pd.read_csv('MovieSummaries/movie.metadata.tsv', sep = '\\t', header = None)\n",
    "load_character = pd.read_csv('MovieSummaries/character.metadata.tsv', sep = '\\t', header = None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = load_movies.copy()\n",
    "character = load_character.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the name of the colum of movie: wikip_ID, freebase_ID, name, release date, box office, runtime, languages, countries, genres\t\n",
    "movies.columns = ['Wiki_ID', 'Freebase_ID', 'name', 'release_date', 'box_office', 'runtime', 'languages', 'countries', 'genres']\n",
    "# Make the name of the columns of character wiki_ID, freebase_ID, character_name, actor_DOB, actor_gender, actor_height, actor_ethnicity, actor_name, actor_age, freebase_character_map\n",
    "character.columns = ['Wiki_ID', 'Freebase_ID','release_date', 'character_name', 'actor_DOB', 'actor_gender', 'actor_height', 'actor_ethnicity', 'actor_name', 'actor_age', '10', '11', '12']\n",
    "character = character.drop(['10', '11', '12'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>Wiki_ID</th>\n",
       "      <th>Freebase_ID</th>\n",
       "      <th>country</th>\n",
       "      <th>movie</th>\n",
       "      <th>gross</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0228333</td>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>ghosts of mars</td>\n",
       "      <td>8709640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0228333</td>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>France</td>\n",
       "      <td>ghosts of mars</td>\n",
       "      <td>1937390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0228333</td>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>Spain</td>\n",
       "      <td>ghosts of mars</td>\n",
       "      <td>509536.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0228333</td>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>Germany</td>\n",
       "      <td>ghosts of mars</td>\n",
       "      <td>496679.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0228333</td>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>ghosts of mars</td>\n",
       "      <td>148898.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90661</th>\n",
       "      <td>tt0120202</td>\n",
       "      <td>1918494</td>\n",
       "      <td>/m/0660qx</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>state and main</td>\n",
       "      <td>13732.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90662</th>\n",
       "      <td>tt0120202</td>\n",
       "      <td>1918494</td>\n",
       "      <td>/m/0660qx</td>\n",
       "      <td>Australia</td>\n",
       "      <td>state and main</td>\n",
       "      <td>385631.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90663</th>\n",
       "      <td>tt0107057</td>\n",
       "      <td>664006</td>\n",
       "      <td>/m/030xw6</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>guilty as sin</td>\n",
       "      <td>22866222.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90664</th>\n",
       "      <td>tt1606259</td>\n",
       "      <td>34980460</td>\n",
       "      <td>/m/0g4pl34</td>\n",
       "      <td>Domestic</td>\n",
       "      <td>knuckle</td>\n",
       "      <td>2647.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90665</th>\n",
       "      <td>tt1606259</td>\n",
       "      <td>34980460</td>\n",
       "      <td>/m/0g4pl34</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>knuckle</td>\n",
       "      <td>22008.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90666 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tconst   Wiki_ID Freebase_ID         country           movie  \\\n",
       "0      tt0228333    975900   /m/03vyhn        Domestic  ghosts of mars   \n",
       "1      tt0228333    975900   /m/03vyhn          France  ghosts of mars   \n",
       "2      tt0228333    975900   /m/03vyhn           Spain  ghosts of mars   \n",
       "3      tt0228333    975900   /m/03vyhn         Germany  ghosts of mars   \n",
       "4      tt0228333    975900   /m/03vyhn  United Kingdom  ghosts of mars   \n",
       "...          ...       ...         ...             ...             ...   \n",
       "90661  tt0120202   1918494   /m/0660qx         Denmark  state and main   \n",
       "90662  tt0120202   1918494   /m/0660qx       Australia  state and main   \n",
       "90663  tt0107057    664006   /m/030xw6        Domestic   guilty as sin   \n",
       "90664  tt1606259  34980460  /m/0g4pl34        Domestic         knuckle   \n",
       "90665  tt1606259  34980460  /m/0g4pl34  United Kingdom         knuckle   \n",
       "\n",
       "            gross  \n",
       "0       8709640.0  \n",
       "1       1937390.0  \n",
       "2        509536.0  \n",
       "3        496679.0  \n",
       "4        148898.0  \n",
       "...           ...  \n",
       "90661     13732.0  \n",
       "90662    385631.0  \n",
       "90663  22866222.0  \n",
       "90664      2647.0  \n",
       "90665     22008.0  \n",
       "\n",
       "[90666 rows x 6 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read grossed merged clean csv\n",
    "gross = pd.read_csv('gross_merged_clean.csv')\n",
    "gross"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "For The first question we will need the gross of the movies in the different region of the world, as well as their release year and their genre.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The release date of the movie is in the format of YYYY-MM-DD, we only need the year \n",
    "# so we split the date and only keep the year\n",
    "movies_clean_release = movies.copy()\n",
    "movies_clean_release['release_date'] = movies_clean_release['release_date'].str[:4]\n",
    "movies_clean_release['release_date'] = pd.to_numeric(movies_clean_release['release_date'], errors='coerce')\n",
    "# Here the errors ignore is to keep the nan in the release date column\n",
    "movies_clean_release['release_date'] = movies_clean_release['release_date'].astype(np.int64, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_clean_genre = movies_clean_release.copy()\n",
    "movies_clean_genre['genres'] = movies_clean_genre['genres'].apply(lambda x: list(ast.literal_eval(x).values()))\n",
    "# This line is to make the empty list to be nan so the nan are uniform\n",
    "movies_clean_genre['genres'] = movies_clean_genre['genres'].apply(lambda x: x if len(x) != 0 else np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "gross_genre_release = gross.copy()\n",
    "#merge gross and movies_clean_genre on wiki_ID\n",
    "gross_genre_release = gross_genre_release.merge(movies_clean_genre[['Wiki_ID', 'release_date', 'genres']], on = 'Wiki_ID', how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of missing values in the genre column is 0.14%\n"
     ]
    }
   ],
   "source": [
    "# count the numers of nan in genre\n",
    "missing_genre_value = gross_genre_release.drop_duplicates(subset='Wiki_ID')['genres'].isna().sum()/gross_genre_release.drop_duplicates(subset='Wiki_ID')['genres'].shape[0]*100\n",
    "print('The percentage of missing values in the genre column is {:.2f}%'.format(missing_genre_value))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a very low percentage of genre missing we can therefore have a good analysis about this metric. We don't have any missing values for the release date because it was used as a key when merging the IMdB dataset with the CMU datset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_clean_country = movies_clean_genre.copy()\n",
    "movies_clean_country['countries'] = movies_clean_country['countries'].apply(lambda x: list(ast.literal_eval(x).values()))\n",
    "# This line is to make the empty list to be nan so the nan are uniform\n",
    "movies_clean_country['countries'] = movies_clean_country['countries'].apply(lambda x: x if len(x) != 0 else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "gross_country = gross.copy()\n",
    "#merge gross and movies_clean_genre on wiki_ID\n",
    "gross_country = gross_country.merge(movies_clean_country[['Wiki_ID', 'countries']], on = 'Wiki_ID', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of missing values in the countries column is 1.70%\n"
     ]
    }
   ],
   "source": [
    "# count the numers of nan in countries\n",
    "missing_country_value = gross_country.drop_duplicates(subset='Wiki_ID')['countries'].isna().sum()/gross_country.drop_duplicates(subset='Wiki_ID')['countries'].shape[0]*100\n",
    "print('The percentage of missing values in the countries column is {:.2f}%'.format(missing_country_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of movies that are co-produced by more than one country is 24.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marcp\\AppData\\Local\\Temp\\ipykernel_9812\\30425266.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  coprood_count = coprood_count.drop_duplicates(subset='Wiki_ID')[coprood_count['countries'].apply(lambda x: len(x)) > 1].shape[0]/gross_country.drop_duplicates(subset='Wiki_ID')['countries'].shape[0]*100\n"
     ]
    }
   ],
   "source": [
    "coprood_count = gross_country.dropna(subset='countries')\n",
    "coprood_count = coprood_count.drop_duplicates(subset='Wiki_ID')[coprood_count['countries'].apply(lambda x: len(x)) > 1].shape[0]/gross_country.drop_duplicates(subset='Wiki_ID')['countries'].shape[0]*100\n",
    "\n",
    "print('The number of movies that are co-produced by more than one country is {:.2f}%'.format(coprood_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a very low percentage of countries missing we can therefore have a good analysis about this metric. And the level of co-production is relatively high so it will still make sense to do our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the gender representation in the moviee. We decided to only use the values that were given for each of the movies, making the assumption that if the gender of an actor is not given the character was probably a small part. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiki_ID\n",
      "330         1.000000\n",
      "3217        0.230769\n",
      "3333        0.428571\n",
      "3746        0.214286\n",
      "3837        0.100000\n",
      "              ...   \n",
      "37373877    0.500000\n",
      "37476824    0.400000\n",
      "37478048    0.250000\n",
      "37492363         NaN\n",
      "37501922    0.500000\n",
      "Length: 64330, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# go in the character dataset and find the percentage of gender F in each movie\n",
    "character_gender = character.copy()\n",
    "\n",
    "#count the number of \"F\" for each wiki_ID in character_gender\n",
    "# groupby wiki_ID and count the number of \"F\" in each group\n",
    "character_groupby = character_gender.groupby('Wiki_ID')\n",
    "character_groupby_tot = character_groupby[\"actor_gender\"].count()\n",
    "character_groupby_F = character_groupby.apply(lambda x: (x['actor_gender'] == 'F').sum())\n",
    "ratio_female_to_total = character_groupby_F / character_groupby_tot\n",
    "print(ratio_female_to_total)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wiki_ID</th>\n",
       "      <th>Freebase_ID</th>\n",
       "      <th>release_date</th>\n",
       "      <th>character_name</th>\n",
       "      <th>actor_DOB</th>\n",
       "      <th>actor_gender</th>\n",
       "      <th>actor_height</th>\n",
       "      <th>actor_ethnicity</th>\n",
       "      <th>actor_name</th>\n",
       "      <th>actor_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>429940</th>\n",
       "      <td>37501922</td>\n",
       "      <td>/m/0c0m5vt</td>\n",
       "      <td>1992</td>\n",
       "      <td>John Hunter</td>\n",
       "      <td>1966-10-11</td>\n",
       "      <td>M</td>\n",
       "      <td>1.765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Luke Perry</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429941</th>\n",
       "      <td>37501922</td>\n",
       "      <td>/m/0c0m5vt</td>\n",
       "      <td>1992</td>\n",
       "      <td>Craig Murphy</td>\n",
       "      <td>1969-07-28</td>\n",
       "      <td>F</td>\n",
       "      <td>1.720</td>\n",
       "      <td>/m/041rx</td>\n",
       "      <td>Alexis Arquette</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Wiki_ID Freebase_ID release_date character_name   actor_DOB  \\\n",
       "429940  37501922  /m/0c0m5vt         1992    John Hunter  1966-10-11   \n",
       "429941  37501922  /m/0c0m5vt         1992   Craig Murphy  1969-07-28   \n",
       "\n",
       "       actor_gender  actor_height actor_ethnicity       actor_name  actor_age  \n",
       "429940            M         1.765             NaN       Luke Perry       25.0  \n",
       "429941            F         1.720        /m/041rx  Alexis Arquette       22.0  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character[character['Wiki_ID']==37501922    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
